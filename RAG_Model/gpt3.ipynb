{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Safety Intervention GPT (NRSH 2025)\n",
    "\n",
    "This RAG (Retrieval-Augmented Generation) system is designed for the National Road Safety Hackathon 2025. It uses a local LLM (Llama 3.2 3B) and a curated vector database (`knowledge_base.json`) to answer questions about road safety interventions, standards, and best practices. \n",
    "\n",
    "It features a multi-step prompt that synthesizes information from multiple sources to provide **comprehensive, topic-wise replies** and **includes citations** as required by the competition rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Python Libraries\n",
    "\n",
    "This cell installs all the necessary Python libraries. OCR-related libraries have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.3.30)\n",
      "Requirement already satisfied: sentence-transformers in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (5.1.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: transformers in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.57.0)\n",
      "Requirement already satisfied: torch in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: accelerate in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.35.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.3.78)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.11.10)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.4.32)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: tqdm in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: scipy in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: Pillow in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: fsspec in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: psutil in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community sentence-transformers faiss-cpu transformers torch accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Set environment variable to avoid tokenizer parallelism warnings\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load and Prepare Documents from `knowledge_base.json`\n",
    "\n",
    "This function loads our pre-curated `knowledge_base.json` file. It transforms each JSON object into a LangChain `Document` object, which separates the text content (for searching) from the metadata (for filtering and citations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and prepared 240 documents from 'knowledge_base.json'.\n",
      "\n",
      "--- Example Document --- \n",
      "Content: STOP Sign. The 'STOP' sign, used on Minor Roads intersecting Major Roads, requires vehicles to stop before entering and proceed only when safe. It is octagonal with a red background, a white border, and \"STOP\" written centrally in white. Installed on the left side of the approach, it should be placed close to the stop line, typically 1.5 m in advance, without impairing visibility of the Major Road.\n",
      "The dimensions vary by approach speed: up to 50 km/h, 750 mm height, 25 mm border, 175 mm font; 51–65 km/h, 900 mm height, 30 mm border, 210 mm font; and over 65 km/h, 1200 mm height, 40 mm border, 280 mm font.\n",
      "Metadata: {'type': 'Standard', 'category': 'Road Sign', 'common_problems_solved': 'Damaged', 'source_reference': 'IRC:67-2022 - Clause 14.4', 'id': 'std-1', 'intervention_name': 'STOP Sign'}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "JSON_FILE_PATH = \"knowledge_base.json\"\n",
    "documents = []\n",
    "\n",
    "def load_and_prepare_documents(file_path):\n",
    "    \"\"\"Loads the curated JSON file and transforms it into a list of LangChain Documents.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        doc_list = []\n",
    "        for item in data:\n",
    "            # Check if the item has the expected structure\n",
    "            if 'full_text' in item and 'metadata' in item:\n",
    "                \n",
    "                # Use the 'full_text' field for embedding and search\n",
    "                page_content = item['full_text']\n",
    "                \n",
    "                # Use the 'metadata' object directly\n",
    "                final_metadata = item['metadata']\n",
    "                \n",
    "                # Add other top-level fields to metadata for reference\n",
    "                final_metadata['id'] = item.get('id', 'N/A')\n",
    "                final_metadata['intervention_name'] = item.get('intervention_name', 'N/A')\n",
    "\n",
    "                doc_list.append(Document(page_content=page_content, metadata=final_metadata))\n",
    "            else:\n",
    "                print(f\"Skipping item with unexpected format: {item.get('id', 'Unknown ID')}\")\n",
    "\n",
    "        return doc_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{file_path}' not found. Please make sure it's in the same directory.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"ERROR: '{file_path}' is not a valid JSON file. Please check for syntax errors.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading and preparing documents: {e}\")\n",
    "        return []\n",
    "\n",
    "documents = load_and_prepare_documents(JSON_FILE_PATH)\n",
    "if documents:\n",
    "    print(f\"Successfully loaded and prepared {len(documents)} documents from '{JSON_FILE_PATH}'.\")\n",
    "    print(\"\\n--- Example Document --- \")\n",
    "    print(f\"Content: {documents[0].page_content}\")\n",
    "    print(f\"Metadata: {documents[0].metadata}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Embeddings and Create Vector Store\n",
    "\n",
    "This step embeds the `Document` objects we created. We use `FAISS.from_documents` to build the vector database in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model and creating vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/cwlrl67n1p3fsjh24d6dk5r00000gn/T/ipykernel_23135/1413067530.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name='BAAI/bge-large-en-v1.5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "vector_store = None\n",
    "if documents:\n",
    "    print(\"Loading embedding model and creating vector store...\")\n",
    "\n",
    "    # Using a reliable and high-performing open-source embedding model\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name='BAAI/bge-large-en-v1.5')\n",
    "    \n",
    "    # Create the vector store from our list of Document objects\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    \n",
    "    print(\"Vector store created successfully.\")\n",
    "else:\n",
    "    print(\"Skipping vector store creation because no documents were loaded from the JSON file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load Llama 3.2 3B Model\n",
    "\n",
    "This step loads the local LLM to act as the 'brain' of our RAG system. You must add your Hugging Face token to download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama 3.2 3B LLM for generation...\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.2 3B LLM loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HF_TOKEN = \"\" # <-- PASTE YOUR TOKEN HERE\n",
    "\n",
    "if HF_TOKEN == \"YOUR_HUGGING_FACE_TOKEN_GOES_HERE\":\n",
    "    print(\"=\"*50)\n",
    "    print(\"ERROR: Please set your Hugging Face token in the HF_TOKEN variable.\")\n",
    "    print(\"Get one from: https://huggingface.co/settings/tokens\")\n",
    "    print(\"=\"*50)\n",
    "    llm_generator = None\n",
    "else:\n",
    "    print(\"Loading Llama 3.2 3B LLM for generation...\")\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    llm_generator = pipeline(\n",
    "        \"text-generation\",\n",
    "model=model,\n",
    "tokenizer=tokenizer,\n",
    "max_new_tokens=1024 # Increased token limit for detailed answers\n",
    "    )\n",
    "    print(\"Llama 3.2 3B LLM loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Define Intents and **Topic-Wise** Prompts\n",
    "\n",
    "This is the new 'brain' of the bot. We're replacing the 'study' intents with 'road safety' intents. \n",
    "\n",
    "Crucially, the `ask_question` prompt is now a **synthesis prompt**. It instructs the AI to find *all* relevant pieces of information, **group them by topic** (like you requested!), and present a comprehensive answer. It also **explicitly commands the AI to cite its sources** from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent_simple(query):\n",
    "    \"\"\"A simple keyword-based intent detection for the road safety bot.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Intent to find a specific standard or specification\n",
    "    if 'what is the standard for' in query_lower or 'standard for' in query_lower or 'rule for' in query_lower or 'specification for' in query_lower:\n",
    "        return 'find_standard'\n",
    "    \n",
    "    # Intent to find an intervention for a specific problem\n",
    "    if 'what should i do about' in query_lower or 'how to fix' in query_lower or 'intervention for' in query_lower or 'my sign is' in query_lower or 'marking is' in query_lower or 'problem is' in query_lower:\n",
    "        return 'find_intervention'\n",
    "    \n",
    "    # Intent to compare two things\n",
    "    if 'difference between' in query_lower or 'compare' in query_lower:\n",
    "        return 'compare_interventions'\n",
    "    \n",
    "    # Default: A general question\n",
    "    return 'ask_question' \n",
    "\n",
    "def generate_content(context_docs, query, intent):\n",
    "    \"\"\"Generates a response based on the detected intent, including citations.\"\"\"\n",
    "    \n",
    "    # We format the context to be crystal clear for the LLM\n",
    "    context_text = \"\\n\\n---\\n\".join([\n",
    "        f\"Source: {doc.metadata.get('source_reference', 'N/A')}\\nContent: {doc.page_content}\"\n",
    "        for doc in context_docs\n",
    "    ])\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "\n",
    "    if intent == 'ask_question' or intent == 'find_standard' or intent == 'find_intervention' or intent == 'compare_interventions':\n",
    "        system_prompt = (\n",
    "            \"You are an Expert Road Safety Analyst for the National Road Safety Hackathon. \"\n",
    "            \"Your task is to provide a comprehensive, well-structured answer based ONLY on the provided context, which contains IRC standards and best practices. \"\n",
    "            \"Do not just answer with the first relevant fact. **Synthesize** information from *all* the provided context documents. \"\n",
    "            \"If you find multiple relevant interventions (e.g., for 'speeding'), **group them by topic** (e.g., 'Engineering Solutions', 'Enforcement Solutions'). \"\n",
    "            \"Be precise, actionable, and **you MUST cite your sources** for every claim you make, using the format [Source]. \"\n",
    "            \"If the context does not contain the information, state that you cannot answer from the provided knowledge base.\"\n",
    "        )\n",
    "        if intent == 'find_standard':\n",
    "            user_prompt = f\"Context from Knowledge Base:\\n{context_text}\\n\\nQuestion: {query}\\n\\nTask: Provide the specific standard or regulation for the user's question. Be detailed and quote the exact specifications (like dimensions, placement, etc.) if available. Cite your source.\"\n",
    "        elif intent == 'find_intervention':\n",
    "             user_prompt = f\"Context from Knowledge Base:\\n{context_text}\\n\\nQuestion: {query}\\n\\nTask: The user has a problem. Recommend specific interventions or standards from the context to solve it. Explain what to do and how it helps. Cite your source.\"\n",
    "        else: # 'ask_question' or 'compare_interventions'\n",
    "            user_prompt = f\"Context from Knowledge Base:\\n{context_text}\\n\\nQuestion: {query}\\n\\nTask: Answer the user's question by synthesizing all relevant context. If comparing, create a clear comparison. Cite your sources.\"\n",
    "\n",
    "    # --- This section is from your original notebook, modified slightly --- #\n",
    "    elif intent == 'request_summary':\n",
    "        system_prompt = \"You are an expert Road Safety Analyst. Create a concise, easy-to-read summary of the key points from the following context. Use bullet points and cite your sources [Source].\"\n",
    "        user_prompt = f\"Context:\\n{context_text}\\n\\nSummary:\"\n",
    "    \n",
    "    elif intent == 'request_quiz':\n",
    "        system_prompt = \"You are an expert Road Safety Analyst. Create an engaging multiple-choice quiz with 3 to 4 questions based on the following context. For each question, provide four options (A, B, C, D), and clearly state the correct answer, citing the source [Source].\"\n",
    "        user_prompt = f\"Context:\\n{context_text}\\n\\nQuiz:\"\n",
    "    # ------------------------------------------------------------------ #\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        response = llm_generator(prompt, num_return_sequences=1) # Ensure only one response is generated\n",
    "        full_response_text = response[0]['generated_text']\n",
    "        \n",
    "        # The model's answer is what comes after the prompt\n",
    "        answer = full_response_text.split(prompt)[-1].strip()\n",
    "        return answer, [doc.metadata.get('source', 'N/A') for doc in context_docs]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM generation: {e}\")\n",
    "        return f\"Sorry, I encountered an error while generating the response: {e}\", []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: The RAG Query Function\n",
    "\n",
    "This function ties everything together. It detects the intent, retrieves context, and then either answers the question or generates content. \n",
    "\n",
    "I've increased `k=5` to retrieve *more* documents. This is key for the \"topic-wise\" synthesis, as it gives the LLM more information to group and summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    if not vector_store or not llm_generator:\n",
    "        print(\"ERROR: Vector store or LLM is not initialized. Please run all preceding steps, including setting your HF_TOKEN.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*20}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    intent = detect_intent_simple(query)\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "    \n",
    "    # Retrieve relevant documents from the vector store\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=5) # Increased to k=5 for better synthesis\n",
    "    \n",
    "    print(f\"Retrieved {len(retrieved_docs)} relevant documents...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate the answer using the LLM and the retrieved context\n",
    "    final_answer, sources = generate_content(retrieved_docs, query, intent)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    content_type = \"Response\"\n",
    "    if intent == 'ask_question' or intent == 'find_standard' or intent == 'find_intervention' or intent == 'compare_interventions':\n",
    "        content_type = 'Answer'\n",
    "    elif intent == 'request_summary':\n",
    "        content_type = 'Summary'\n",
    "    elif intent == 'request_quiz':\n",
    "        content_type = 'Quiz'\n",
    "\n",
    "    print(f\"\\n✅ {content_type} (generated in {end_time - start_time:.2f}s):\")\n",
    "    print(final_answer)\n",
    "    \n",
    "    # This is for your reference, to see what the bot was 'thinking'\n",
    "    print(\"\\n--- Retrieved Sources ---\")\n",
    "    unique_sources = sorted(list(set(sources)))\n",
    "    for i, source in enumerate(unique_sources):\n",
    "        print(f\"Source {i+1}: {source}\")\n",
    "    print(f\"{'='*20}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Example Queries\n",
    "\n",
    "Let's test our new Road Safety GPT! Uncomment the queries to run them. **You must run the cells above this one first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Query: My sign is faded and not retro-reflective. What's the rule for that?\n",
      "Detected Intent: find_standard\n",
      "Retrieved 5 relevant documents...\n",
      "\n",
      "✅ Answer (generated in 23.90s):\n",
      "Based on the provided context, I can provide the relevant information for the user's question. According to the IRC:67-2022 - Clause 14.6.22, the standard for retro-reflective regulatory signs, including the signs for \"STOP\", \"GIVE WAY\", and \"SPEED LIMIT\", states that:\n",
      "\n",
      "\"The retro-reflective sheeting used shall cover the entire surface, be weather-resistant, colorfast, and free from defects, with a minimum coefficient of retro-reflection in accordance with ASTM D 4956 standards.\"\n",
      "\n",
      "This implies that the sign's retro-reflective sheeting must be of a certain quality and meet specific standards.\n",
      "\n",
      "However, it does not explicitly state the rule for replacing or replacing faded and non-retro-reflective signs.\n",
      "\n",
      "But, according to the IRC:67-2022 - Clause 13.3, the sign shall be replaced either at the end of the warranty period of the retro-reflective sheeting or if its reflectivity falls below 80 percent.\n",
      "\n",
      "Therefore, the specific standard or regulation for replacing a faded and non-retro-reflective sign is:\n",
      "\n",
      "* The sign shall be replaced either at the end of the warranty period of the retro-reflective sheeting or if its reflectivity falls below 80 percent of the initial reflectivity.\n",
      "\n",
      "Source: IRC:67-2022 - Clause 13.3\n",
      "\n",
      "--- Retrieved Sources ---\n",
      "Source 1: N/A\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_query(\"My sign is faded and not retro-reflective. What's the rule for that?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test Queries (Uncomment and run one by one in a new cell) --- \n",
    "\n",
    "# 1. Test a specific standard (from your table data)\n",
    "# process_query(\"What is the standard for a STOP sign?\")\n",
    "\n",
    "# 2. Test a problem-based intervention (from your table data)\n",
    "# process_query(\"My sign is faded and not retro-reflective. What's the rule for that?\")\n",
    "\n",
    "# 3. Test a broad, topic-wise question (should get multiple answers from your intervention data)\n",
    "# process_query(\"What interventions can I use for speeding in a school zone?\")\n",
    "\n",
    "# 4. Test a comparison question (for topic-wise synthesis)\n",
    "# process_query(\"What is the difference between a speed hump and a rumble strip?\")\n",
    "\n",
    "# 5. Test a quiz intent\n",
    "# process_query(\"quiz me on road signs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Query: What interventions can I use for speeding in a school zone?\n",
      "Detected Intent: ask_question\n",
      "Retrieved 5 relevant documents...\n",
      "\n",
      "✅ Answer (generated in 34.43s):\n",
      "Based on the provided context, here are the interventions for speeding in a school zone:\n",
      "\n",
      "**Engineering Solutions:**\n",
      "\n",
      "1. **Speed Humps**: Vertical calming devices that reduce vehicle speeds to safe walking speeds, particularly effective on minor roads around schools. (Source: WHO Inspired)\n",
      "2. **Speed Limit 20/30 kmph Zones**: Strictly enforced low-speed zones using signs and calming measures, ideal for school opening and closing hours or dense urban corridors. (Source: WHO Inspired)\n",
      "3. **School Zone Warning Signs**: Highly visible signs, such as SCHOOL AHEAD boards, placed before school entrances to alert drivers to slow down proactively. (Source: MoRTH Inspired)\n",
      "\n",
      "**Enforcement Solutions:**\n",
      "\n",
      "1. **School Zone Enforcement Cameras**: CCTV or radar-based systems monitoring speeding and improper parking, particularly effective in accident-prone or high-volume school corridors. (Source: MoRTH Inspired)\n",
      "\n",
      "**Comparison:**\n",
      "\n",
      "| Intervention | Effectiveness | Suitable for |\n",
      "| --- | --- | --- |\n",
      "| Speed Humps | Reduces vehicle speeds | Minor roads around schools |\n",
      "| Speed Limit 20/30 kmph Zones | Reduces crash severity | School opening and closing hours, dense urban corridors |\n",
      "| School Zone Warning Signs | Alerts drivers to slow down | All school frontages and nearby pedestrian conflict points |\n",
      "| School Zone Enforcement Cameras | Ensures compliance with speed and parking rules | Accident-prone or high-volume school corridors |\n",
      "\n",
      "It's essential to consider the specific context of the school zone, including the road type, volume of traffic, and pedestrian activity, when selecting an intervention. (Source: MoRTH Inspired)\n",
      "\n",
      "In general, a combination of engineering solutions (e.g., speed humps, speed limit zones) and enforcement solutions (e.g., cameras) can be effective in reducing speeding in school zones. (Source: WHO Inspired)\n",
      "\n",
      "References:\n",
      "\n",
      "* WHO Inspired. (No date). Speed Humps in School Zones. Retrieved from <https://www.who.int/>\n",
      "* MoRTH Inspired. (No date). Safe School Zone Design. Retrieved from <https://www.morth.gov.in/>\n",
      "* MoRTH Inspired. (No date). School Zone Enforcement Cameras. Retrieved from <https://www.morth.gov.in/>\n",
      "* WHO Inspired. (No date). Speed Limit 20/30 kmph Zones. Retrieved from <https://www.who.int/>\n",
      "\n",
      "--- Retrieved Sources ---\n",
      "Source 1: N/A\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_query(\"What interventions can I use for speeding in a school zone?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Query: My road markings are faded and not retro-reflective. What's the rule for that?\n",
      "Detected Intent: find_standard\n",
      "Retrieved 5 relevant documents...\n",
      "\n",
      "✅ Answer (generated in 33.03s):\n",
      "Based on the provided context, the rule for faded and non-retro-reflective road markings is outlined in the IRC:35-2015 - Clause 2.7 and PWD Inspired.\n",
      "\n",
      "According to IRC:35-2015 - Clause 2.7, road markings must be clearly visible day and night, providing essential guidance, especially on unlit roads. Drivers shall detect markings at least two seconds ahead and that minimum preview distance with respect to speed is as follows: For <30 km/h: 17 m; 30–40 km/h: 22 m; 40–50 km/h: 28 m; 50–65 km/h: 36 m; 65–70 km/h: 39 m; 70–80 km/h: 44 m; 80–90 km/h: 50 m; 90–100 km/h: 56 m; 100–110 km/h: 61 m; 110–120 km/h: 67 m.\n",
      "\n",
      "However, there is no specific rule for faded and non-retro-reflective markings. The only relevant information provided is that visibility improves with wider lines, higher mark-to-gap ratios, and increased retro-reflectivity. These factors help drivers detect the markings according to design speed of roadway.\n",
      "\n",
      "For thermoplastic road markings, which are commonly used for centerlines, edge lines, arrows, and zebra crossings, the IRC:35-2015 - Clause 2.2 states that highly durable thermoplastic pavement material offers better retro-reflective performance and a longer service life than ordinary road marking paint. However, this does not address the issue of faded markings.\n",
      "\n",
      "The PWD Inspired provides guidance on lane marking refurbishment, which includes repainting faded lane markings for clarity. According to PWD Inspired, this is recommended when there are intersections with poor visibility, as it improves lane discipline and reduces side-swipe crashes. However, this is not directly related to the issue of faded and non-retro-reflective markings.\n",
      "\n",
      "Since there is no specific rule for faded and non-retro-reflective markings, it is recommended to refer to the relevant standards and guidelines for road markings, such as the IRC:35-2015 - Clause 2.7 and the PWD Inspired guidelines.\n",
      "\n",
      "**References:**\n",
      "\n",
      "IRC:35-2015 - Clause 2.7\n",
      "IRC:35-2015 - Clause 2.2\n",
      "PWD Inspired\n",
      "\n",
      "--- Retrieved Sources ---\n",
      "Source 1: N/A\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_query(\"My road markings are faded and not retro-reflective. What's the rule for that?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
