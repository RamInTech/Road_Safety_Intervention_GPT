{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Safety Intervention GPT (NRSH 2025)\n",
    "\n",
    "This RAG (Retrieval-Augmented Generation) system is designed for the National Road Safety Hackathon 2025. It uses a local LLM (Llama 3.2 3B) and a curated vector database (`knowledge_base.json`) to answer questions about road safety interventions, standards, and best practices. \n",
    "\n",
    "It features a multi-step prompt that synthesizes information from multiple sources to provide **comprehensive, topic-wise replies** and **includes citations** as required by the competition rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Python Libraries\n",
    "\n",
    "This cell installs all the necessary Python libraries. OCR-related libraries have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.3.30)\n",
      "Requirement already satisfied: sentence-transformers in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (5.1.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: transformers in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.57.0)\n",
      "Requirement already satisfied: torch in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: accelerate in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.35.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.3.78)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.4.32)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: scipy in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: tqdm in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: Pillow in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: filelock in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: psutil in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: anyio in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community sentence-transformers faiss-cpu transformers torch accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ram/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Set environment variable to avoid tokenizer parallelism warnings\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load and Prepare Documents from `knowledge_base.json`\n",
    "\n",
    "This function loads our pre-curated `knowledge_base.json` file. It's designed to intelligently handle **both** of the JSON formats you provided:\n",
    "1.  The IRC Standards format (with `s_no`, `problem`, `data`, `code`, `clause`).\n",
    "2.  The Intervention Strategy format (with `id`, `intervention`, `description`).\n",
    "\n",
    "It transforms each JSON object into a unified LangChain `Document` object, which separates the text content (for searching) from the metadata (for filtering and citations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and prepared 240 documents from 'knowledge_base.json'.\n",
      "\n",
      "--- Example Document --- \n",
      "Intervention/Standard: STOP Sign\n",
      "Details: The 'STOP' sign, used on Minor Roads intersecting Major Roads, requires vehicles to stop before entering and proceed only when safe. It is octagonal with a red background, a white border, and \"STOP\" written centrally in white. Installed on the left side of the approach, it should be placed close to the stop line, typically 1.5 m in advance, without impairing visibility of the Major Road.\n",
      "The dimensions vary by approach speed: up to 50 km/h, 750 mm height, 25 mm border, 175 mm font; 51–65 km/h, 900 mm height, 30 mm border, 210 mm font; and over 65 km/h, 1200 mm height, 40 mm border, 280 mm font.\n",
      "{'source': 'IRC:67-2022 - Clause 14.4', 'type': 'Standard', 'category': 'Road Sign', 'problems': 'Damaged'}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "JSON_FILE_PATH = \"knowledge_base.json\"\n",
    "documents = []\n",
    "\n",
    "def load_and_prepare_documents(file_path):\n",
    "    \"\"\"Loads the curated JSON file and transforms it into a list of LangChain Documents.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        doc_list = []\n",
    "        for item in data:\n",
    "            # Use 'intervention_name' as a key to detect our 'gold standard' format\n",
    "            # (This is the format produced by the transformation script I provided earlier)\n",
    "            if 'intervention_name' in item:\n",
    "                page_content = f\"Intervention/Standard: {item['intervention_name']}\\nDetails: {item['content']}\"\n",
    "                metadata = item.get('metadata', {})\n",
    "                final_metadata = {\n",
    "                    'source': metadata.get('source_reference', 'N/A'),\n",
    "                    'type': metadata.get('type', 'N/A'),\n",
    "                    'category': metadata.get('category', 'N/A'),\n",
    "                    'problems': metadata.get('common_problems_solved', 'N/A')\n",
    "                }\n",
    "            \n",
    "            # Fallback for your 'IRC Standard' table format\n",
    "            elif 's_no' in item and 'data' in item:\n",
    "                page_content = f\"Standard: {item['type']}\\nSpecification: {item['data']}\"\n",
    "                final_metadata = {\n",
    "                    'source': f\"{item.get('code', 'N/A')}, Clause {item.get('clause', 'N/A')}\",\n",
    "                    'type': item.get('category', 'Standard'),\n",
    "                    'category': item.get('category', 'N/A'),\n",
    "                    'problems': item.get('problem', 'N/A')\n",
    "                }\n",
    "\n",
    "            # Fallback for your 'Intervention Strategy' format\n",
    "            elif 'intervention' in item and 'description' in item:\n",
    "                content_text = (\n",
    "                    f\"{item['description']}. \"\n",
    "                    f\"When to Apply: {item.get('when_to_apply', 'N/A')}. \"\n",
    "                    f\"Why it Works: {item.get('why_it_works', 'N/A')}. \"\n",
    "                    f\"Constraints: {item.get('constraints', 'N/A')}.\"\n",
    "                )\n",
    "                page_content = f\"Intervention: {item['intervention']}\\nDetails: {content_text}\"\n",
    "                final_metadata = {\n",
    "                    'source': item.get('source', 'N/A'),\n",
    "                    'type': 'Intervention',\n",
    "                    'category': item.get('category', 'N/A'),\n",
    "                    'problems': f\"Solution for {item.get('category', 'N/A')}\"\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                print(f\"Skipping unrecognized item: {item.get('id', 'N/A')}\")\n",
    "                continue\n",
    "                \n",
    "            doc_list.append(Document(page_content=page_content, metadata=final_metadata))\n",
    "        \n",
    "        return doc_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{file_path}' not found. Please make sure it's in the same directory.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"ERROR: '{file_path}' is not a valid JSON file. Please check for syntax errors.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading and preparing documents: {e}\")\n",
    "        return []\n",
    "\n",
    "documents = load_and_prepare_documents(JSON_FILE_PATH)\n",
    "if documents:\n",
    "    print(f\"Successfully loaded and prepared {len(documents)} documents from '{JSON_FILE_PATH}'.\")\n",
    "    print(\"\\n--- Example Document --- \")\n",
    "    print(documents[0].page_content)\n",
    "    print(documents[0].metadata)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Embeddings and Create Vector Store\n",
    "\n",
    "This step embeds the `Document` objects we created. We use `FAISS.from_documents` to build the vector database in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model and creating vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/cwlrl67n1p3fsjh24d6dk5r00000gn/T/ipykernel_18660/1413067530.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name='BAAI/bge-large-en-v1.5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "vector_store = None\n",
    "if documents:\n",
    "    print(\"Loading embedding model and creating vector store...\")\n",
    "\n",
    "    # Using a reliable and high-performing open-source embedding model\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name='BAAI/bge-large-en-v1.5')\n",
    "    \n",
    "    # Create the vector store from our list of Document objects\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    \n",
    "    print(\"Vector store created successfully.\")\n",
    "else:\n",
    "    print(\"Skipping vector store creation because no documents were loaded from the JSON file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load Llama 3.2 3B Model\n",
    "\n",
    "This step loads the local LLM to act as the 'brain' of our RAG system. You must add your Hugging Face token to download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama 3.2 3B LLM for generation...\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.2 3B LLM loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HF_TOKEN = \"\" # <-- PASTE YOUR TOKEN HERE\n",
    "\n",
    "if HF_TOKEN == \"\":\n",
    "    print(\"=\"*50)\n",
    "    print(\"ERROR: Please set your Hugging Face token in the HF_TOKEN variable.\")\n",
    "    print(\"Get one from: https://huggingface.co/settings/tokens\")\n",
    "    print(\"=\"*50)\n",
    "    llm_generator = None\n",
    "else:\n",
    "    print(\"Loading Llama 3.2 3B LLM for generation...\")\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    llm_generator = pipeline(\n",
    "        \"text-generation\",\n",
    "model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=1024 # Increased token limit for detailed answers\n",
    "    )\n",
    "    print(\"Llama 3.2 3B LLM loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Define Intents and **Topic-Wise** Prompts\n",
    "\n",
    "This is the upgraded 'brain' of the bot. We're replacing the 'study' intents with 'road safety' intents. \n",
    "\n",
    "Crucially, the `ask_question` prompt is now a **synthesis prompt**. It instructs the AI to find *all* relevant pieces of information, **group them by topic** (like I do!), and present a comprehensive answer, not just the first chunk it finds. It also **explicitly commands the AI to cite its sources** from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent_simple(query):\n",
    "    \"\"\"A simple keyword-based intent detection function.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    if 'summarize' in query_lower or 'summary' in query_lower:\n",
    "        return 'request_summary'\n",
    "    if 'quiz' in query_lower or 'test me' in query_lower or 'flashcard' in query_lower:\n",
    "        return 'request_quiz'\n",
    "    return 'ask_question' \n",
    "\n",
    "def generate_content(context_docs, query, intent):\n",
    "    \"\"\"Generates a response, summary, or quiz based on the intent.\"\"\"\n",
    "    \n",
    "    # We format the context to be crystal clear for the LLM\n",
    "    context_text = \"\\n\\n---\\n\".join([\n",
    "        f\"Source: {doc.metadata.get('source', 'N/A')}\\nContent: {doc.page_content}\"\n",
    "        for doc in context_docs\n",
    "    ])\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "\n",
    "    if intent == 'ask_question':\n",
    "        system_prompt = (\n",
    "            \"You are an expert Road Safety Analyst for the National Road Safety Hackathon. \"\n",
    "            \"Your task is to provide a comprehensive, well-structured answer based ONLY on the provided context, which contains IRC standards and best practices. \"\n",
    "            \"Do not just answer with the first relevant fact. **Synthesize** information from *all* the provided context documents. \"\n",
    "            \"If you find multiple relevant interventions (e.g., for 'speeding'), **group them by topic** (e.g., 'Engineering Solutions', 'Enforcement Solutions'). \"\n",
    "            \"Be precise, actionable, and **you MUST cite your sources** for every claim you make, using the format [Source]. \"\n",
    "            \"If the context does not contain the information, state that you cannot answer from the provided knowledge base.\"\n",
    "        )\n",
    "        user_prompt = f\"Context from Knowledge Base:\\n{context_text}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    elif intent == 'request_summary':\n",
    "        system_prompt = \"You are an expert Road Safety Analyst. Create a concise, easy-to-read summary of the key points from the following context. Use bullet points and cite your sources [Source].\"\n",
    "        user_prompt = f\"Context:\\n{context_text}\\n\\nSummary:\"\n",
    "    \n",
    "    elif intent == 'request_quiz':\n",
    "        system_prompt = \"You are an expert Road Safety Analyst. Create an engaging multiple-choice quiz with 3 to 4 questions based on the following context. For each question, provide four options (A, B, C, D), and clearly state the correct answer, citing the source [Source].\"\n",
    "        user_prompt = f\"Context:\\n{context_text}\\n\\nQuiz:\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        response = llm_generator(prompt, num_return_sequences=1)\n",
    "        full_response_text = response[0]['generated_text']\n",
    "        \n",
    "        answer = full_response_text.split(prompt)[-1].strip()\n",
    "        return answer, [doc.metadata.get('source', 'N/A') for doc in context_docs]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM generation: {e}\")\n",
    "        return f\"Sorry, I encountered an error while generating the response: {e}\", []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: The RAG Query Function\n",
    "\n",
    "This function ties everything together. It detects the intent, retrieves context, and then either answers the question or generates content. \n",
    "\n",
    "I've increased `k=5` to retrieve *more* documents. This is key for the \"topic-wise\" synthesis, as it gives the LLM more information to group and summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    if not vector_store or not llm_generator:\n",
    "        print(\"ERROR: Vector store or LLM is not initialized. Please run all preceding steps.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*20}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    intent = detect_intent_simple(query)\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "    \n",
    "    # Retrieve relevant documents from the vector store\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=5) # Increased to k=5 for better synthesis\n",
    "    \n",
    "    print(f\"Retrieved {len(retrieved_docs)} relevant documents...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate the answer using the LLM and the retrieved context\n",
    "    final_answer, sources = generate_content(retrieved_docs, query, intent)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    content_type = \"Response\"\n",
    "    if intent == 'ask_question':\n",
    "        content_type = 'Answer'\n",
    "    elif intent == 'request_summary':\n",
    "        content_type = 'Summary'\n",
    "    elif intent == 'request_quiz':\n",
    "        content_type = 'Quiz'\n",
    "\n",
    "    print(f\"\\n✅ {content_type} (generated in {end_time - start_time:.2f}s):\")\n",
    "    print(final_answer)\n",
    "    \n",
    "    # This is for your reference, to see what the bot was 'thinking'\n",
    "    print(\"\\n--- Retrieved Sources ---\")\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        print(f\"Doc {i+1} Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "        # print(f\"Doc {i+1} Content: {doc.page_content[:100]}...\") # Uncomment for debugging\n",
    "    print(f\"{'='*20}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Example Queries\n",
    "\n",
    "Let's test our new Road Safety GPT! Uncomment the queries to run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test Queries (Uncomment and run one by one) --- \n",
    "\n",
    "# 1. Test a specific standard (from your table data)\n",
    "# process_query(\"What is the standard for a STOP sign?\")\n",
    "\n",
    "# 2. Test a problem-based intervention (from your table data)\n",
    "# process_query(\"My road markings are faded and not retro-reflective. What's the rule for that?\")\n",
    "\n",
    "# 3. Test a broad, topic-wise question (should get multiple answers)\n",
    "# process_query(\"What interventions can I use for speeding?\")\n",
    "\n",
    "# 4. Test a summary intent\n",
    "# process_query(\"summarize the standards for speed humps and rumble strips\")\n",
    "\n",
    "# 5. Test a quiz intent\n",
    "# process_query(\"quiz me on road signs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Query: What is the standard for a STOP sign?\n",
      "Detected Intent: ask_question\n",
      "Retrieved 5 relevant documents...\n",
      "\n",
      "✅ Answer (generated in 17.52s):\n",
      "According to the provided context, the standard for a STOP sign, as outlined in IRC:67-2022 - Clause 14.4, is as follows:\n",
      "\n",
      "- The 'STOP' sign is octagonal in shape with a red background, a white border, and \"STOP\" written centrally in white.\n",
      "- It is installed on the left side of the approach, close to the stop line, typically 1.5 m in advance, without impairing visibility of the Major Road.\n",
      "- The dimensions vary by approach speed:\n",
      "  - Up to 50 km/h, 750 mm height, 25 mm border, 175 mm font.\n",
      "  - 51–65 km/h, 900 mm height, 30 mm border, 210 mm font.\n",
      "  - Over 65 km/h, 1200 mm height, 40 mm border, 280 mm font.\n",
      "\n",
      "[Source: IRC:67-2022 - Clause 14.4]\n",
      "\n",
      "--- Retrieved Sources ---\n",
      "Doc 1 Source: IRC:67-2022 - Clause 14.4\n",
      "Doc 2 Source: IRC:67-2022 - Clause 14.4\n",
      "Doc 3 Source: IRC:67-2022 - Clause 14.8.4\n",
      "Doc 4 Source: WHO Inspired\n",
      "Doc 5 Source: IRC:67-2022 - Clause 14.6.22\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_query(\"What is the standard for a STOP sign?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Query: My road markings are faded and not retro-reflective. What's the rule for that?\n",
      "Detected Intent: ask_question\n",
      "Retrieved 5 relevant documents...\n",
      "\n",
      "✅ Answer (generated in 26.69s):\n",
      "Based on the provided context, it appears that the road markings on your road are not meeting the standards for visibility, particularly for drivers to detect the markings at least two seconds ahead.\n",
      "\n",
      "According to the IRC:35-2015 - Clause 2.7, road markings must be clearly visible day and night, providing essential guidance, especially on unlit roads. The minimum preview distance with respect to speed for drivers to detect markings is specified in the table.\n",
      "\n",
      "Since your road markings are faded and not retro-reflective, it is likely that they are not meeting the visibility requirements.\n",
      "\n",
      "The PWD Inspired standard recommends repainting faded lane markings for clarity, especially in intersections with poor visibility. This could be a suitable solution to address the issue.\n",
      "\n",
      "Additionally, the WHO Inspired standard suggests using durable white/yellow thermoplastic markings for centerlines, edge lines, arrows, and zebra crossings. These markings can improve night visibility and skid resistance, which may help address the visibility issue.\n",
      "\n",
      "However, it is essential to note that the specific solution should be determined by considering factors such as the road type, traffic volume, and maintenance requirements.\n",
      "\n",
      "It is recommended to consult with a qualified professional or the relevant authorities to determine the best course of action for repainting or replacing the road markings.\n",
      "\n",
      "References:\n",
      "- IRC:35-2015 - Clause 2.7: Road markings must be clearly visible day and night, providing essential guidance, especially on unlit roads.\n",
      "- PWD Inspired: Repainting faded lane markings for clarity, especially in intersections with poor visibility.\n",
      "- WHO Inspired: Durable white/yellow thermoplastic markings for centerlines, edge lines, arrows, and zebra crossings.\n",
      "\n",
      "--- Retrieved Sources ---\n",
      "Doc 1 Source: IRC:35-2015 - Clause 2.7\n",
      "Doc 2 Source: IRC:35-2015 - Clause 2.7\n",
      "Doc 3 Source: PWD Inspired\n",
      "Doc 4 Source: WHO Inspired\n",
      "Doc 5 Source: IRC:35-2015 - Clause 5.3\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_query(\"My road markings are faded and not retro-reflective. What's the rule for that?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
